Скачайте по одному из указанных ниже адресов и установить на компьютере морфологический анализатор для русского языка. Провести тестирование системы

    1. Проанализируйте систему тегов:

1.1. Сколько частей речи учитывает система; какие части речи в системе отсутствуют, а Вы считаете, что эти части речи необходимо выделять (ответ мотивируйте)
	Всего выделяется 16 частей речи.
1.2. В какие pos-классы попадают местоимения
	pronoun, (pronominal-adj -местоименные прилагательные), (pronominal-adv -местоименные наречия)
1.3. Как лемматизируются причастия?
	страдательные - до формы именительного падежа (POS - Q), действительные - до инфинитива глагола (и POS у них тоже V)
1.4. К одной или разным леммам будет отнесены словоформы нашедший и находившего, дал и давал
	Дал и давал - к одной (давать), нашедший и находившего - к разным (находить) (находившего - лемматизации не произошло)
1.5. Напишите правило пересчета тегов системы на теги из ЗС для анафорических местоимений (он, она и т.п.) и наречий
	cases = {"N":"nom",	"G":"gen",	"D":"dat",	"F":"acc",
	"C":"ins",	"O":"loc",	"P":"partitive",	"L":"locative",
	"V":"vocative"}
	numbers = {"S":"sg", "P":"pl"}
	pos = {"E":"SPRO", "R":"APRO", "Q":"ADV"}
	nclass = {"M":"m", "F":"f", "N":"n", "C":"c"}
	def parse_tag(tag):
		if pos[tag[0]] in ["E", "R"]:
    			return "%s   %s,%s,%s" % (pos[tag[0]], cases[tag[1]], nclass[tag[3]], numbers[tag[2]])
		elif pos[tag[0]] == "Q":
			return "ADV"
		else: raise ValueError("Неожиданный тег.")

    2. Проведите функциональное тестирование выбранной Вами программы. 

2.1. Для этого подберите примеры, содержащие сложные и проблемные случаи для морфологического анализа: например, незнакомые слова, случаи различных типов омонимии, сложные случаи с точки зрения определения частей речи (например, отглагольное прилагательное vs. причастие, частица vs. союз, наречие vs. краткое прилагательное и т.д.)
2.2. Ответьте на следующие вопросы:
2.2.1. Как решаются проблемы токенизации: что происходит с числами, десятичными числами, сокращениями типа г., словами с дефисами, апострофом, знаками препинания? спецзнаками типа $ или &, смешанными элементами (буквы+цифры, вкраплениями другого алфавита) etc.?
	Числа имеют свои категории, даты выделяются отдельно и нормализуются (хотя довольно фигово), диакритики рассматриваются как отдельные символы (Дже́бель-Ирху́д токенизуется как дже ' бель-Ирху ' д). Пунктуация имеет набор тегов по символам плюс тег для всего, что не входит в другие теги.
	Слова в другом алфавите получают более-менее бессмысленную полупустую разметку - они не несущим информации образом приписываются к какой-то части речи, но почти все характеристики этой части речи будут указаны как 0.
2.2.2. Что происходит с незнакомыми словами? Насколько хорошо предсказываются их грамматические характеристики, их леммы?
	Грамматические характеристики по окончаниям предсказываются резонно, но судя по всему, они не лемматизируются вообще.
2.2.3. Что происходит с омонимичными словоформами: предлагается только один максимально вероятный вариант, предлагаются все возможные варианты, предлагаются все варианты, за исключением очень маловероятных случаев или случаев, снимаемых "надежными" правилами и т.п.
	Один максимально вероятный вариант.
2.2.4. Какие проблемные случаи омонимичных разборов разбираются хорошо, в каких часто возникают ошибки и т.п. (например, (а) частеречная омонимия: прилагательное vs. существительное, глагол vs. прилагательное, наречие vs. частица; (б) падежная омонимия; (в) омонимия различных ме6стоименных форм и т.д.)

    3. Обработайте с помощью морфологического анализатора файл. 

Ответ сохраните / преобразуйте в следующий формат:
Каждый токен на отдельной строке – лемма, часть речи, полный грамматический тег. Каждое поле отделяется табуляцией. Знаки препинания, числа, служебные знаки: скобки, слэш и т.п. на отдельной строке. См. файл Золотого стандарта.
Для 500 словоформ из файла ЗС определите:

    уровень оставшейся неоднозначности: число элементов в Output(W) для всех слов тестируемого текста, поделенное на число слов в тексте. Если алгоритм работает однозначно, то этот параметр равняется 1.
	Система работает однозначно.
    лексическая точность алгоритма - число слов текста, для которых лемма приписана правильно, поделенное на общее число слов которым система приписала какие-то теги
	accuracy = 0.874

NB если система приписывает леммы всем словоформам текста, то говорят не о точности и полноте, а об accuracy

    точность - число слов текста, для которых хотя бы одна аннотация правильна (в случае морфологического анализа без дизамбигуации) / аннотация правильна, поделенное на общее число токенов в тексте, которым приписан хотя бы какой-то разбор (если всем токенам что-то приписано, говорят об accuracy).
    accyracy – отношение числа правильно разобранных словоупотреблений (токенов) к числу словоупотреблений (токенов) в тексте (опять же, если система приписывает разборы не всем словам в тексте).


